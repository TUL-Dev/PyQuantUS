from typing import Tuple, List

import numpy as np
from scipy.signal import hilbert

from pyquantus.utc.objects import UltrasoundImage3d, AnalysisConfig3d, Window3d
from pyquantus.utc.transforms import computeHanningPowerSpec3D, computeSpectralParams, map1dTo3d
from scipy.ndimage import binary_closing

class UtcAnalysis3d:
    """Complete ultrasound tissue characterization (UTC) analysis of an ultrasound image given 
    a corresponding phantom image.

    This class supports both scan converted and non-scan converted images. UTC analysis
    is performed on each window generated by the `generatevoiWindows` method. Utc 
    analysis corresponds to the computation of tissue characterization-related parameters.
    The midband fit, spectral slope, and spectral intercept parameters have been validated using
    the frequency domain of each window. The Nakagami parameters, attenuation coefficient,
    backscatter coefficient, effective scatterer diameter, and effective scatterer concentration
    all have been implemented and reviewed, but still have not been validated in practice.

    Attributes:
        ultrasoundImage (UltrasoundImage): Stores image and RF info for image and phantom.
        config (AnalysisConfig): Stores analysis configuration parameters.
        voiWindows (List[Window]): List of windows generated by `generateVoiWindows`.
        waveLength (float): Wavelength of the ultrasound signal in mm.
        nakagamiParams (Tuple): Nakagami parameters (w, u) for the entire ROI.
        attenuationCoef (float): Attenuation coefficient of the entire ROI at the center frequency (dB/cm/MHz).
        backScatterCoef (float): Backscatter coefficient of the entire ROI at the center frequency (1/cm-sr).
        effectiveScattererDiameter (float): Effective scatterer diameter of the entire ROI (µm).
        effectiveScattererConcentration (float): Effective scatterer concentration of the entire ROI (dB/mm^3).
        refAttenuation (float): Total attenuation coefficient of the reference phantom at the center frequency (dB/cm/MHz).
        refBackScatterCoef (float): Backscatter coefficient of the reference phantom at the center frequency (1/cm-sr).
        scSplineX (np.ndarray): Spline x-coordinates in scan converted coordinates.
        splineX (np.ndarray): Spline x-coordinates in pre-scan converted coordinates.
        scSplineY (np.ndarray): Spline y-coordinates in scan converted coordinates.
        splineY (np.ndarray): Spline y-coordinates in pre-scan converted coordinates.
    """
    
    def __init__(self):
        self.ultrasoundImage: UltrasoundImage3d
        self.config: AnalysisConfig3d
        self.voiWindows: List[Window3d] = []
        self.waveLength: float
        self.nakagamiParams: Tuple
        self.attenuationCoef: float
        self.refBackScatterCoef: float
        self.refAttenuation: float
        self.backScatterCoef: float

        self.scSegMask: np.ndarray
        self.segMask: np.ndarray

    def initAnalysisConfig(self):
        """Compute the wavelength of the ultrasound signal and 
        set default config values if not pre-loaded.
        """
        speedOfSoundInTissue = 1540  # m/s
        self.waveLength = (
            speedOfSoundInTissue / self.config.centerFrequency
        ) * 1000  # mm
        if not hasattr(self.config, 'axWinSize'): # not pre-loaded config
            self.config.axWinSize = 10 * self.waveLength
            self.config.latWinSize = 10 * self.waveLength
            self.config.axialOverlap = 0.5; self.config.lateralOverlap = 0.5
            self.config.windowThresh = 0.95

    def splineToPreSc(self):
        """Convert spline coordinates from scan converted to pre-scan converted coordinates."""
        preScBmode = self.ultrasoundImage.bmode
        coordMap = self.ultrasoundImage.coordMap3d
        voiMask = self.scSegMask
        maskedCoords3d = np.transpose(np.where(voiMask))
        originalCoords3d = []
        for coord in maskedCoords3d:
            originalCoords3d.append(map1dTo3d(coordMap[coord[0], coord[1], coord[2]], preScBmode.shape[0], preScBmode.shape[1], preScBmode.shape[2]))
        # Create a blank 3D mask with the same shape as the pre-scan converted B-mode image
        self.segMask = np.zeros_like(preScBmode, dtype=np.uint8)
        self.segMask[tuple(np.transpose(originalCoords3d))] = 1
        self.segMask = binary_closing(self.segMask, structure=np.ones((3, 3, 3))).astype(np.uint8)

    def generateVoiWindows(self):
        """Generate 3D voxel windows for UTC analysis based on user-defined spline."""
        # Some axial/lateral/coronal dims
        axialPixSize = round(self.config.axWinSize / self.ultrasoundImage.axialResRf) # mm/(mm/pix)
        lateralPixSize = round(self.config.latWinSize / self.ultrasoundImage.lateralResRf) # mm(mm/pix)
        coronalPixSize = round(self.config.corWinSize / self.ultrasoundImage.coronalResRf) # mm/(mm/pix)
        
        # Overlap fraction determines the incremental distance between windows
        axialIncrement = axialPixSize * (1 - self.config.axialOverlap)
        lateralIncrement = lateralPixSize * (1 - self.config.lateralOverlap)
        coronalIncrement = coronalPixSize * (1 - self.config.coronalOverlap)

        # Determine windows - Find Volume to Iterate Over
        axialStart = np.min(np.where(np.any(self.segMask, axis=(0, 1)))[0])
        axialEnd = np.max(np.where(np.any(self.segMask, axis=(0, 1)))[0])
        lateralStart = np.min(np.where(np.any(self.segMask, axis=(0, 2)))[0])
        lateralEnd = np.max(np.where(np.any(self.segMask, axis=(0, 2)))[0])
        coronalStart = np.min(np.where(np.any(self.segMask, axis=(1, 2)))[0])
        coronalEnd = np.max(np.where(np.any(self.segMask, axis=(1, 2)))[0])

        self.voiWindows = []

        for axialPos in np.arange(axialStart, axialEnd, axialIncrement):
            for lateralPos in np.arange(lateralStart, lateralEnd, lateralIncrement):
                for coronalPos in np.arange(coronalStart, coronalEnd, coronalIncrement):
                    # Convert axial, lateral, and coronal positions to indices
                    axialInd = np.round(axialPos).astype(int)
                    lateralInd = np.round(lateralPos).astype(int)
                    coronalInd = np.round(coronalPos).astype(int)
                    
                    # Determine if window is inside analysis volume
                    maskVals = self.segMask[
                        coronalInd : (coronalInd + coronalPixSize),
                        lateralInd : (lateralInd + lateralPixSize),
                        axialInd : (axialInd + axialPixSize),
                    ]

                    # Define Percentage Threshold
                    totalNumberOfElementsInRegion = maskVals.size
                    numberOfOnesInRegion = len(np.where(maskVals == True)[0])
                    percentageOnes = numberOfOnesInRegion / totalNumberOfElementsInRegion
                    
                    if percentageOnes > self.config.windowThresh:
                        # Add ROI to output structure, quantize back to valid distances
                        newWindow = Window3d()
                        newWindow.axMin = int(axialPos)
                        newWindow.axMax = int(axialPos + axialPixSize)
                        newWindow.latMin = int(lateralPos)
                        newWindow.latMax = int(lateralPos + lateralPixSize)
                        newWindow.corMin = int(coronalPos)
                        newWindow.corMax = int(coronalPos + coronalPixSize)
                        self.voiWindows.append(newWindow)
                
    def computeUtcWindows(self, extraParams=True, bscFreq=None) -> int:
        """Compute UTC parameters for each window in the ROI.
        
        extraParams (bool): Flag on whether to compute non-validated parameters.
        bscFreq (int): Frequency on which to compute backscatter coefficient (MHz).
        
        Returns:
            int: 0 if successful, -1 if `generatevoiWindows` has not been 
            run or if windows are too large for ROI.
        """
        if not len(self.voiWindows):
            print("Run 'generatevoiWindows' first")
            return -1
        
        if bscFreq is None:
            bscFreq = self.config.centerFrequency
    
        fs = self.config.samplingFrequency
        f0 = self.config.transducerFreqBand[0]
        f1 = self.config.transducerFreqBand[1]
        lowFreq = self.config.analysisFreqBand[0]
        upFreq = self.config.analysisFreqBand[1]

        # Compute MBF, SS, and SI parameters for each window
        for window in self.voiWindows:
            # Compute normalized power spectrum (dB)
            imgWindow = self.ultrasoundImage.rf[window.corMin: window.corMax+1, 
                                               window.latMin: window.latMax+1, 
                                               window.axMin: window.axMax+1]
            refWindow = self.ultrasoundImage.phantomRf[window.corMin: window.corMax+1,
                                                       window.latMin: window.latMax+1, 
                                                       window.axMin: window.axMax+1]
            
            f, ps = computeHanningPowerSpec3D(
                imgWindow, f0, f1, fs
            ) 
            ps = 20 * np.log10(ps)
            f, rPs = computeHanningPowerSpec3D(
                refWindow, f0, f1, fs
            )
            rPs = 20 * np.log10(rPs)
            nps = np.asarray(ps) - np.asarray(rPs)

            window.results.nps = nps
            window.results.ps = np.asarray(ps)
            window.results.rPs = np.asarray(rPs)
            window.results.f = np.asarray(f)

            # Compute MBF, SS, and SI
            mbf, _, _, p = computeSpectralParams(nps, f, lowFreq, upFreq)
            window.results.mbf = mbf # dB
            window.results.ss = p[0]*1e6 # dB/MHz
            window.results.si = p[1] # dB

        minAxial = min([window.axMin for window in self.voiWindows])
        maxAxial = max([window.axMax for window in self.voiWindows])
        minLateral = min([window.latMin for window in self.voiWindows])
        maxLateral = max([window.latMax for window in self.voiWindows])
        minCoronal = min([window.corMin for window in self.voiWindows])
        maxCoronal = max([window.corMax for window in self.voiWindows])
        
        if extraParams:
            # Compute attenuation coefficient
            imgWindow = self.ultrasoundImage.rf[minCoronal: maxCoronal+1, 
                                               minLateral: maxLateral+1, 
                                               minAxial: maxAxial+1]
            refWindow = self.ultrasoundImage.phantomRf[minCoronal: maxCoronal+1,
                                                       minLateral: maxLateral+1, 
                                                       minAxial: maxAxial+1]
            self.attenuationCoef = self.computeAttenuationCoef(imgWindow, refWindow)
            self.backScatterCoef = self.computeBackscatterCoefficient(imgWindow, refWindow, bscFreq, roiDepth=minAxial)
            self.nakagamiParams = self.computeNakagamiParams(imgWindow)
            # self.effectiveScattererDiameter, self.effectiveScattererConcentration = self.computeEsdac(imgWindow, refWindow, apertureRadiusCm=6)
        return 0
    
    def computeAttenuationCoef(self, rfData: np.ndarray, refRfData: np.ndarray, overlap=50, windowDepth=100) -> float:
        """Compute the local attenuation coefficient of the ROI using the Spectral Difference
        Method for Local Attenuation Estimation. This method computes the attenuation coefficient
        for multiple frequencies and returns the slope of the attenuation as a function of frequency.
        Args:
            rfData (np.ndarray): RF data of the ROI (n lines x m samples).
            refRfData (np.ndarray): RF data of the phantom (n lines x m samples).
            overlap (float): Overlap percentage for analysis windows.
            windowDepth (int): Depth of each window in samples.
        Returns:
            float: Local attenuation coefficient of the ROI for the central frequency (dB/cm/MHz).
            Updated and verified : Feb 2025 - IR
        """
        samplingFrequency = self.config.samplingFrequency
        startFrequency = self.config.analysisFreqBand[0]
        endFrequency = self.config.analysisFreqBand[1]
        # Initialize arrays for storing intensities (log of power spectrum for each frequency)
        psSample = [];  # ROI power spectra
        psRef = [];  # Phantom power spectra
        startIdx = 0
        endIdx = windowDepth
        windowCenterIndices = []
        counter = 0
        # Loop through the windows in the RF data
        while endIdx < rfData.shape[0]:
            subWindowRf = rfData[startIdx: endIdx]
            f, ps = computeHanningPowerSpec3D(subWindowRf, startFrequency, endFrequency, samplingFrequency)
            psSample.append(20*np.log10(ps))  # Log scale intensity for the ROI
            refSubWindowRf = refRfData[startIdx: endIdx]
            refF, refPs = computeHanningPowerSpec3D(refSubWindowRf, startFrequency, endFrequency, samplingFrequency)
            psRef.append(20*np.log10(refPs))  # Log scale intensity for the phantom
            windowCenterIndices.append((startIdx + endIdx) // 2)
            startIdx += int(windowDepth*(1-(overlap/100)))
            endIdx = startIdx + windowDepth
            counter += 1
        # Convert window depths to cm
        axialResCm = self.ultrasoundImage.axialResRf / 10
        windowDepthsCm = np.array(windowCenterIndices) * axialResCm
        attenuationCoefficients = []  # One coefficient for each frequency
        f = f / 1e6
        psSample = np.array(psSample)
        psRef = np.array(psRef)
        midIdx = f.shape[0] // 2  # Middle index
        startIdx = max(0, midIdx - 25)  # Start index for slicing
        endIdx = min(f.shape[0], midIdx + 25)  # End index for slicing
        # Compute attenuation for each frequency
        for fIdx in range(startIdx, endIdx):
            normalizedIntensities = np.subtract(psSample[:, fIdx], psRef[:, fIdx])
            #p = np.polyfit(windowDepthsCm, normalizedIntensities, 1)
            A = windowDepthsCm.reshape(-1, 1)  # or windowDepthsCm[:, np.newaxis]
            p, _, _, _ = np.linalg.lstsq(A, normalizedIntensities, rcond=None)
            localAttenuation = self.refAttenuation * f[fIdx] - (1 / 4) * p[0]  # dB/cm
            attenuationCoefficients.append( localAttenuation / f[fIdx])  # dB/cm/MHz
        attenuationCoef=np.mean(attenuationCoefficients)
        return attenuationCoef
    
    def computeBackscatterCoefficient(self, rfData: np.ndarray, refRfData: np.ndarray,
                                      frequency: int, roiDepth: int) -> float:
        """Compute the backscatter coefficient of the ROI using the reference phantom method.
        Assumes instrumentation and beam terms have the same effect on the signal from both 
        image and phantom. 
        source: Mamou & Oelze, page 52: https://doi.org/10.1007/978-94-007-6952-6

        Args:
            rfData (np.ndarray): RF data of the ROI (n lines x m samples).
            refRfData (np.ndarray): RF data of the phantom (n lines x m samples).
            roiDepth (int): Depth of the start of the ROI in samples.
            frequency (int): Frequency on which to compute backscatter coefficient (MHz).
            refAttenuation (float): Attenuation coefficient of the reference phantom.
            
        Returns:
            float: Backscatter coefficient of the ROI for the central frequency (1/cm-sr).
        """
        f, ps = computeHanningPowerSpec3D(rfData, self.config.analysisFreqBand[0], self.config.analysisFreqBand[1],
                                     self.config.samplingFrequency)
        _, refPs = computeHanningPowerSpec3D(refRfData, self.config.analysisFreqBand[0], self.config.analysisFreqBand[1],
                                     self.config.samplingFrequency)
        
        ps = ps[len(f)//2]
        refPs = refPs[len(f)//2]
        axialResM = self.ultrasoundImage.axialResRf/1000 # m
        depthDistance = roiDepth*axialResM + 0.5*rfData.shape[0]*axialResM # m, center of ROI
        
        npConversionFactor = np.log(10) / 20 
        convertedAttCoef = self.attenuationCoef * npConversionFactor / 100 # dB/cm/MHz -> Np/m/MHz
        convertedRefAttCoef = self.refAttenuation * npConversionFactor / 100 # dB/cm/MHz -> Np/m/MHz
        convertedAttCoef *= frequency # Np/m
        convertedRefAttCoef *= frequency # Np/m
        
        bsc = (ps/refPs)*self.refBackScatterCoef*np.exp(4*depthDistance*(convertedAttCoef - convertedRefAttCoef)) # 1/cm/sr
        return bsc
        
    def computeNakagamiParams(self, rfData: np.ndarray) -> Tuple[float, float]:
        """Compute Nakagami parameters for the ROI.
        source: Tsui, P. H., Wan, Y. L., Huang, C. C. & Wang, M. C. 
        Effect of adaptive threshold filtering on ultrasonic Nakagami 
        parameter to detect variation in scatterer concentration. Ultrason. 
        Imaging 32, 229–242 (2010). https://doi.org/10.1177%2F016173461003200403

        Args:
            rfData (np.ndarray): RF data of the ROI (n lines x m samples).
            
        Returns:
            Tuple: Nakagami parameters (w, u) for the ROI.
        """
        
        r = np.abs(hilbert(rfData, axis=1))
        w = np.nanmean(r ** 2, axis=1)
        u = (w ** 2) / np.var(r ** 2, axis=1)

        # Added this to get single param values
        w = np.nanmean(w)
        u = np.nanmean(u)

        return w, u
    
    def computeEsdac(self, rfData: np.ndarray, refRfData: np.ndarray, apertureRadiusCm: float) -> Tuple[float, float]:
        """Compute the effective scatterer diameter and concentration of the ROI.
        source: Muleki-Seya et al. https://doi.org/10.1177/0161734617729159
        
        Args:
            rfData (np.ndarray): RF data of the ROI (n lines x m samples).
            refRfData (np.ndarray): RF data of the phantom (n lines x m samples).
            apertureRadiusCm (float): Aperture radius in cm.
            roiDepth (int): Depth of the start of the ROI in samples.
            
        Returns:
            Tuple: Effective scatterer diameter (µm) and concentration of the ROI (dB/mm^3).
        """
        windowDepthCm = rfData.shape[0]*self.ultrasoundImage.axialResRf/10 # cm
        windowLengthCm = rfData.shape[1]*self.ultrasoundImage.lateralResRf/10 # cm. Assuming this unit, but not explicitly stated in paper
        q = apertureRadiusCm / windowDepthCm

        f, ps = computeHanningPowerSpec3D(rfData, self.config.analysisFreqBand[0], self.config.analysisFreqBand[1],
                                     self.config.samplingFrequency)
        _, refPs = computeHanningPowerSpec3D(refRfData, self.config.analysisFreqBand[0], self.config.analysisFreqBand[1],
                                     self.config.samplingFrequency)
        
        ps = 10*np.log10(ps) # dB
        refPs = 10*np.log10(refPs) # dB
        
        f *= 1e-6 # Hz -> MHz
        s = np.subtract(ps-refPs, 10*np.log10(f**4))
        p = np.polyfit(f**2, s, 1)
        m = abs(p[0])
        b1 = p[1]
        esd = 2*(m/((11.6*(q**2))+52.8)) ** 0.5 # µm

        b0 = self.attenuationCoef
        eac = 64 * (
            (10 ** ((b1 + 2*windowDepthCm*b0) / 10)) 
            / (185 * windowLengthCm * (q**2) * esd**6)
        ) # dB/mm^3

        return esd, eac